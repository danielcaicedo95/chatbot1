# app/services/conversation.py

from datetime import datetime
import json
import re
import traceback
from difflib import get_close_matches
from typing import List, Dict, Any, Tuple, Optional

from app.utils.memory import user_histories
from app.clients.gemini import ask_gemini_with_history
from app.clients.whatsapp import send_whatsapp_message, send_whatsapp_image # ASUMO QUE YA SON ASYNC DEF
from app.services.supabase import save_message_to_supabase
from app.services.products import get_all_products # get_recommended_products (se usar√° si es necesario)
# from app.services.orders import process_order # La l√≥gica de procesar orden se integra m√°s con el LLM
from app.utils.extractors import extract_order_data

# --- Constantes y Configuraciones ---
DEFAULT_SHIPPING_COST = 5000
# Campos requeridos que el LLM debe obtener ANTES de generar el JSON de la orden.
# El JSON de la orden tendr√° m√°s campos (productos, total, etc.)
REQUIRED_USER_DATA_FOR_ORDER = ["name", "address", "phone", "payment_method"]


# --- Funciones Auxiliares de Productos y Cat√°logo ---

def _get_product_variant_text(variant: Dict) -> str:
    """Genera un texto descriptivo para una variante (ej: 'Amarillo, 750ml')."""
    options_parts = []
    for key, value in variant.get("options", {}).items():
        options_parts.append(str(value))
    return ", ".join(options_parts) if options_parts else "Est√°ndar"

def _find_product_in_list(products: List[Dict], query_name: str) -> Optional[Dict]:
    """Encuentra un producto por nombre (exacto o aproximado)."""
    if not query_name: return None
    query_lower = query_name.lower()
    
    for p in products:
        if p["name"].lower() == query_lower:
            return p
    
    product_names = [p["name"].lower() for p in products]
    matches = get_close_matches(query_lower, product_names, n=1, cutoff=0.7)
    if matches:
        matched_name = matches[0]
        for p in products:
            if p["name"].lower() == matched_name:
                return p
    return None

def _find_variant_in_product(product: Dict, query_variant_text: str) -> Optional[Dict]:
    """Encuentra una variante dentro de un producto por su texto descriptivo."""
    if not query_variant_text or not product: return None
    query_lower = query_variant_text.lower()

    for v in product.get("product_variants", []):
        variant_text = _get_product_variant_text(v).lower()
        if query_lower in variant_text: # Permite "amarillo" encontrar "Tequila Amarillo"
            return v
        
        # B√∫squeda por coincidencia cercana en las opciones individuales
        option_values = [str(opt_val).lower() for opt_val in v.get("options", {}).values()]
        matches = get_close_matches(query_lower, option_values, n=1, cutoff=0.7)
        if matches and matches[0] in variant_text:
            return v
            
    return None

def _get_image_urls(product: Dict, variant: Optional[Dict] = None) -> List[str]:
    """Obtiene URLs de im√°genes, priorizando las de variante si se especifica."""
    urls = []
    all_images = product.get("product_images", [])

    if variant:
        variant_id = variant.get("id")
        # Buscar im√°genes asociadas directamente a la variante
        urls.extend([img["url"] for img in all_images if img.get("variant_id") == variant_id])

    # Si no se especific√≥ variante, o la variante no tiene im√°genes propias, buscar im√°genes generales del producto.
    # Se podr√≠a decidir si agregar generales solo si las de variante est√°n vac√≠as.
    # Aqu√≠, si se pidi√≥ variante y tiene im√°genes, solo se muestran esas. Sino, se muestran las generales.
    if not urls: # O si queremos siempre agregar las generales: if True:
        urls.extend([img["url"] for img in all_images if img.get("variant_id") is None])
    
    return list(set(urls)) # Eliminar duplicados

def _build_simplified_catalog_for_llm_image_detection(products: List[Dict]) -> List[Dict]:
    """Crea un resumen del cat√°logo (nombres y variantes) para ayudar al LLM."""
    summary = []
    for p in products:
        item = {"name": p["name"], "variants": []}
        for v in p.get("product_variants", []):
            item["variants"].append(_get_product_variant_text(v))
        summary.append(item)
    return summary

def _build_detailed_catalog_for_llm_sales(products: List[Dict]) -> str:
    """Construye la descripci√≥n del cat√°logo para el prompt de ventas del LLM."""
    lines = ["üõçÔ∏è **Nuestro Cat√°logo de Productos** (Precios en COP):\n"]
    for p in products:
        product_info = f"**{p['name']}**"
        if p.get('description'):
            product_info += f"\n   üìù _{p['description'][:150]}..._" # Descripci√≥n corta
        
        variants = p.get("product_variants", [])
        if variants:
            product_info += "\n   üé® Variantes disponibles:"
            for v in variants:
                v_text = _get_product_variant_text(v)
                price = v.get("price", p.get("price", "Precio no disponible"))
                stock = v.get("stock", "Consultar stock")
                product_info += f"\n     - {v_text}: ${price:,.0f} (Stock: {stock})"
        elif p.get("price") is not None and p.get("price") > 0:
            price = p.get("price", "Precio no disponible")
            stock = p.get("stock", "Consultar stock")
            product_info += f"\n   üí∞ Precio: ${price:,.0f} (Stock: {stock})"
        else:
             product_info += "\n   ‚ÑπÔ∏è (Consultar precio y disponibilidad)"
        lines.append(product_info)
    return "\n\n".join(lines)


# --- Funciones de Interacci√≥n con LLM y Env√≠o ---

async def _get_llm_image_intent(
    user_history: List[Dict], current_user_message: str, catalog_summary: List[Dict]
) -> Optional[Dict]:
    """Determina si el usuario quiere im√°genes y de qu√©, usando el LLM."""
    prompt_instructions = [
        "Tu tarea es analizar el √öLTIMO mensaje del usuario en el CONTEXTO del historial de conversaci√≥n y el cat√°logo proporcionado.",
        "Determina si el usuario est√° solicitando ver im√°genes de un producto o variante.",
        "Si pide im√°genes, responde con un JSON: {\"action\": \"show_image\", \"product_name\": \"<nombre_producto_del_catalogo>\", \"variant_text\": \"<texto_variante_del_catalogo_o_mencion_usuario>\"}.",
        "   - `product_name` debe ser lo m√°s cercano posible a un nombre del cat√°logo.",
        "   - `variant_text` puede ser el texto descriptivo de la variante (ej: 'amarillo', 'azul', '750ml') o null si no se especifica.",
        "   - Si el usuario dice 'm√°ndame foto' y antes hablaron de 'Tequila Jose Cuervo', usa ese contexto.",
        "Si el usuario NO pide im√°genes, responde con un JSON: {\"action\": \"continue_conversation\"}.",
        "Ejemplos de solicitud de imagen:",
        "   User: 'foto del tequila amarillo' -> {\"action\": \"show_image\", \"product_name\": \"Tequila Jose Cuervo\", \"variant_text\": \"amarillo\"}",
        "   User: 'imagen del aguardiente nari√±o azul' -> {\"action\": \"show_image\", \"product_name\": \"Aguardiente Nari√±o\", \"variant_text\": \"azul\"}",
        "   User: 'tienes fotos?' (Contexto previo: hablando de Ron) -> {\"action\": \"show_image\", \"product_name\": \"<Nombre del Ron del contexto>\", \"variant_text\": null}",
        "Responde √öNICAMENTE con el JSON."
    ]
    
    # Solo los √∫ltimos mensajes relevantes para el historial de Gemini
    relevant_history = [m for m in user_history if m["role"] in ("user", "model")][-6:]
    
    llm_input_payload = {
        "history": relevant_history,
        "current_user_message": current_user_message,
        "catalog_summary_for_reference": catalog_summary, # Para que el LLM tenga nombres
        "instructions": prompt_instructions
    }
    
    # El prompt para Gemini debe ser una lista de mensajes
    llm_prompt_messages = relevant_history + [
        {"role": "user", "text": json.dumps(llm_input_payload, ensure_ascii=False)}
    ]

    try:
        llm_response_str = await ask_gemini_with_history(llm_prompt_messages)
        print(f"üß† Respuesta LLM (intenci√≥n imagen): {llm_response_str}")
        
        # Extraer el JSON de la respuesta (Gemini a veces a√±ade ```json ... ```)
        match = re.search(r"\{[\s\S]*\}", llm_response_str)
        if match:
            action_json = json.loads(match.group())
            if action_json.get("action") == "show_image" and action_json.get("product_name"):
                return action_json
    except json.JSONDecodeError:
        print(f"‚ö†Ô∏è Error decodificando JSON de LLM para intenci√≥n de imagen: {llm_response_str}")
    except Exception as e:
        print(f"‚ö†Ô∏è Error en _get_llm_image_intent: {e}\n{traceback.format_exc()}")
    return None


async def _send_requested_images(
    from_number: str, product: Dict, variant: Optional[Dict], user_history: List[Dict]
):
    """Env√≠a las im√°genes del producto/variante y actualiza el historial."""
    image_urls = _get_image_urls(product, variant)
    
    product_display_name = product['name']
    if variant:
        product_display_name += f" ({_get_product_variant_text(variant)})"

    if not image_urls:
        response_text = f"üòî Lo siento, no tenemos im√°genes disponibles para *{product_display_name}* en este momento."
        await send_whatsapp_message(from_number, response_text)
    else:
        response_text = f"¬°Claro! Aqu√≠ tienes las im√°genes de *{product_display_name}*:"
        await send_whatsapp_message(from_number, response_text)
        for i, url in enumerate(image_urls):
            try:
                # Si hay muchas im√°genes, solo la primera con caption completo o sin caption.
                caption = product_display_name if i == 0 and len(image_urls) > 1 else "" 
                if len(image_urls) == 1: caption = product_display_name

                await send_whatsapp_image(from_number, url, caption=caption)
            except Exception as e_img:
                print(f"‚ùå Error enviando imagen {url} para {from_number}: {e_img}")
                await send_whatsapp_message(from_number, "‚ö†Ô∏è Hubo un problema al enviar una de las im√°genes, pero aqu√≠ est√°n las otras (si hay).")
        response_text = f"Envi√© im√°genes de {product_display_name}." # Para el historial interno

    user_history.append({"role": "model", "text": response_text, "time": datetime.utcnow().isoformat()})
    await save_message_to_supabase(from_number, "model", response_text) # Guardar la acci√≥n en Supabase


async def _handle_sales_conversation_with_llm(
    from_number: str,
    user_message_text: str,
    user_history: List[Dict],
    all_products: List[Dict]
):
    """Maneja el flujo de ventas principal usando el LLM."""
    
    catalog_context_for_llm = _build_detailed_catalog_for_llm_sales(all_products)

    # Instrucciones detalladas para el LLM vendedor
    sales_instructions = [
        "Eres 'Vendebot ü§ñ', un asistente de ventas virtual amigable, proactivo y muy eficiente. Tu objetivo es ayudar al cliente y cerrar ventas.",
        "Usa emojis para hacer la conversaci√≥n m√°s cercana y humana. üòäüõíüçæ",
        "**TU PROCESO DE VENTA:**",
        "1.  **Saludo y Escucha Activa**: Responde al usuario amablemente. Si hace preguntas sobre productos, usa la informaci√≥n del cat√°logo proporcionado.",
        "2.  **Identificar Intenci√≥n de Compra**: Si el usuario expresa deseo de comprar ('quiero X', 'me interesa Y', 'cu√°nto por Z'):",
        "    a.  Ayuda a armar el carrito: Confirma producto(s), variante(s) y cantidad(es).",
        "    b.  Calcula el subtotal de los productos.",
        f"    c.  Informa sobre el costo de env√≠o fijo: COP {DEFAULT_SHIPPING_COST:,.0f}.",
        "    d.  Presenta el TOTAL del pedido (subtotal + env√≠o).",
        "    e.  PREGUNTA SIEMPRE: '¬øDeseas agregar algo m√°s a tu pedido?' Puedes sugerir UN producto complementario de forma sutil si es relevante.",
        "3.  **Recopilaci√≥n de Datos (SIEMPRE DESPU√âS DE CONFIRMAR EL CARRITO Y QUE NO QUIERE M√ÅS PRODUCTOS)**:",
        "    Cuando el usuario confirme que est√° listo para finalizar o diga 'no quiero nada m√°s', PIDE DE FORMA CLARA Y ORDENADA los siguientes datos para el env√≠o:",
        "      - Nombre completo.",
        "      - Direcci√≥n de entrega detallada (incluyendo barrio/ciudad).",
        "      - N√∫mero de tel√©fono de contacto (si es diferente al de WhatsApp).",
        "      - M√©todo de pago (ej: 'Efectivo contra entrega', 'Transferencia Bancolombia', 'Nequi').",
        "    *NO ASUMAS NING√öN DATO. P√çDELOS EXPL√çCITAMENTE.*",
        "4.  **Confirmaci√≥n Final y JSON del Pedido (SOLO CUANDO TENGAS TODOS LOS DATOS DEL PUNTO 3 Y EL CARRITO EST√â DEFINIDO)**:",
        "    a.  Resume el pedido completo: productos (con variante y cantidad), subtotal, env√≠o, total, y los datos de entrega del usuario.",
        "    b.  Pide una √∫ltima confirmaci√≥n: '¬øEs todo correcto para procesar tu pedido?'",
        "    c.  Si el usuario confirma, A√ëADE AL FINAL DE TU MENSAJE DE CONFIRMACI√ìN el siguiente bloque JSON EXACTO, rellenando los campos. NO incluyas el JSON si faltan datos o si el usuario no ha confirmado.",
        "        ```json",
        "        {\"order_details\":{\"name\":\"<NOMBRE_COMPLETO>\",\"address\":\"<DIRECCION_DETALLADA>\",\"phone\":\"<TELEFONO_CONTACTO>\",\"payment_method\":\"<METODO_PAGO>\",\"products\":[{\"name\":\"<NOMBRE_PROD_1>\",\"variant_text\":\"<TEXTO_VARIANTE_1 (si aplica)>\",\"quantity\":<CANT_1>,\"price_unit\":<PRECIO_UNIT_1>}, ...otros_productos],\"subtotal_products\":<SUBTOTAL_PRODS>,\"shipping_cost\":<COSTO_ENVIO>,\"total_order\":<TOTAL_PEDIDO>}}",
        "        ```",
        "5.  **Manejo de Stock**: Si un producto/variante est√° agotado o con bajo stock seg√∫n el cat√°logo, informa y sugiere alternativas.",
        "6.  **Preguntas Generales**: Si no hay intenci√≥n de compra, solo responde preguntas usando el cat√°logo.",
        "7.  **Claridad**: Si no entiendes algo, pide amablemente una aclaraci√≥n.",
        "**Cat√°logo de Referencia:**",
        catalog_context_for_llm,
        "\n**Historial de Conversaci√≥n Reciente:**"
    ]

    # El prompt para Gemini debe ser una lista de mensajes
    relevant_history = [m for m in user_history if m["role"] in ("user", "model")][-10:]
    llm_prompt_messages = relevant_history + [
        {"role": "user", "text": user_message_text + "\n\n" + "\n".join(sales_instructions)}
    ]
    
    llm_response_str = await ask_gemini_with_history(llm_prompt_messages)
    print(f"üß† Respuesta LLM (ventas): {llm_response_str}")

    # `extract_order_data` debe manejar la separaci√≥n del JSON y el texto limpio.
    # Tambi√©n debe validar que el `order_data` (si existe) sea completo.
    order_data, clean_bot_response = extract_order_data(llm_response_str, DEFAULT_SHIPPING_COST)

    if not clean_bot_response and not order_data: # Si LLM no da respuesta usable
        clean_bot_response = "Hmm, no estoy seguro de c√≥mo responder a eso. ¬øPodr√≠as intentarlo de otra manera? ü§î"
    
    if clean_bot_response:
        await send_whatsapp_message(from_number, clean_bot_response)
        user_history.append({"role": "model", "text": clean_bot_response, "time": datetime.utcnow().isoformat()})
        await save_message_to_supabase(from_number, "model", clean_bot_response)

    if order_data:
        print(f"üì¶ Datos de orden extra√≠dos y listos para guardar: {json.dumps(order_data, indent=2)}")
        # Aqu√≠ es donde guardar√≠as `order_data` en tu tabla de pedidos de Supabase.
        # Ejemplo: await save_order_to_supabase_orders_table(from_number, order_data)
        # El mensaje de "pedido procesado" ya deber√≠a haberlo dado el LLM como parte de `clean_bot_response`
        # si sigui√≥ las instrucciones de incluir el JSON *despu√©s* de la confirmaci√≥n verbal.
        # Si no, puedes enviar un mensaje de confirmaci√≥n gen√©rico adicional aqu√≠.
        # await send_whatsapp_message(from_number, "‚úÖ ¬°Tu pedido ha sido registrado con √©xito! Gracias por tu compra. üéâ")
    else:
        # Esto significa que el LLM est√° en una etapa de la conversaci√≥n que no implica un pedido finalizado.
        # (ej: pidiendo datos, confirmando carrito, etc.)
        print("‚ÑπÔ∏è No se extrajeron datos de orden finalizados en esta interacci√≥n.")


# --- Handler Principal de Mensajes de Usuario ---

async def handle_user_message(body: dict):
    try:
        entry = body.get("entry", [{}])[0]
        changes = entry.get("changes", [{}])[0]
        message_obj = changes.get("value", {}).get("messages", [{}])[0]

        if message_obj.get("type") != "text": # Ignorar estados, multimedia del usuario, etc.
            print(f"‚ÑπÔ∏è Mensaje no textual recibido (tipo: {message_obj.get('type')}). Ignorando.")
            return

        user_text = message_obj.get("text", {}).get("body", "").strip()
        from_number = message_obj.get("from")

        if not user_text or not from_number:
            print("‚ö†Ô∏è Mensaje vac√≠o o sin remitente. Ignorando.")
            return

        print(f"üí¨ Mensaje de {from_number}: '{user_text}'")

        # Inicializar/recuperar historial
        user_history = user_histories.setdefault(from_number, [])
        user_history.append({"role": "user", "text": user_text, "time": datetime.utcnow().isoformat()})
        await save_message_to_supabase(from_number, "user", user_text)

        all_products = await get_all_products()
        if not all_products:
            await send_whatsapp_message(from_number, "‚ö†Ô∏è Lo siento, estoy teniendo problemas para acceder a nuestro cat√°logo. Intenta m√°s tarde.")
            return

        # 1. Comprobar si el usuario est√° pidiendo im√°genes
        catalog_summary_for_img_detection = _build_simplified_catalog_for_llm_image_detection(all_products)
        image_intent_details = await _get_llm_image_intent(user_history, user_text, catalog_summary_for_img_detection)

        image_request_handled_successfully = False
        if image_intent_details and image_intent_details.get("action") == "show_image":
            product_name = image_intent_details.get("product_name")
            variant_text = image_intent_details.get("variant_text")
            
            found_product = _find_product_in_list(all_products, product_name)
            found_variant = None
            if found_product and variant_text:
                found_variant = _find_variant_in_product(found_product, variant_text)
            
            if found_product:
                await _send_requested_images(from_number, found_product, found_variant, user_history)
                image_request_handled_successfully = True # Indica que se gestion√≥ una solicitud de imagen (incluso si no se encontraron)
                # El flujo continuar√°, y el LLM de ventas tendr√° el contexto de que se enviaron im√°genes.
                # Se podr√≠a a√±adir un mensaje tipo: "¬øTe gustar√≠a a√±adirlo al carrito o tienes m√°s preguntas sobre este producto?"
                # await send_whatsapp_message(from_number, "¬øTe gustar√≠a a√±adir este producto al carrito o tienes m√°s preguntas? üòä")
                # return # Si queremos detener el flujo aqu√≠ y esperar nueva respuesta del usuario.
                # Por ahora, dejaremos que el flujo contin√∫e al LLM de ventas.
            else:
                no_product_msg = f"Hmm, mencionaste '{product_name}' pero no lo encuentro en nuestro cat√°logo. ¬øPodr√≠as verificar el nombre? ü§î"
                await send_whatsapp_message(from_number, no_product_msg)
                user_history.append({"role": "model", "text": no_product_msg, "time": datetime.utcnow().isoformat()})
                await save_message_to_supabase(from_number, "model", no_product_msg)
                image_request_handled_successfully = True # Se intent√≥ manejar
        
        # 2. Continuar con el flujo de ventas/conversaci√≥n general.
        # El LLM de ventas recibir√° el mensaje original del usuario y el historial actualizado (que puede incluir la interacci√≥n de im√°genes).
        await _handle_sales_conversation_with_llm(
            from_number,
            user_text, # El mensaje original del usuario para que el LLM de ventas lo procese.
            user_history,
            all_products
        )

    except Exception as e:
        error_message = f"‚ùå [ERROR CR√çTICO en handle_user_message]: {e}\n{traceback.format_exc()}"
        print(error_message)
        # Intentar notificar al usuario del error si es posible
        if 'from_number' in locals() and from_number:
            try:
                await send_whatsapp_message(from_number, "ü§ñ ¬°Ups! Algo no sali√≥ bien de mi lado. Por favor, int√©ntalo de nuevo en un momento. üôè")
            except Exception as e_send:
                print(f"üí£ [FALLO AL ENVIAR MENSAJE DE ERROR AL USUARIO]: {e_send}")